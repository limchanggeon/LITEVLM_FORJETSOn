# LiteVLM on Jetson - í”„ë¡œì íŠ¸ ìš”ì•½

## ğŸ“¦ ìƒì„±ëœ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
liteVLM_injetson/
â”œâ”€â”€ README.md                    # í”„ë¡œì íŠ¸ ë©”ì¸ ë¬¸ì„œ
â”œâ”€â”€ QUICKSTART.md                # ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
â”œâ”€â”€ DEVELOPMENT.md               # ê°œë°œì ê°€ì´ë“œ
â”œâ”€â”€ LICENSE                      # MIT ë¼ì´ì„ ìŠ¤
â”œâ”€â”€ requirements.txt             # Python ì˜ì¡´ì„±
â”œâ”€â”€ environment.yml              # Conda í™˜ê²½ ì„¤ì •
â”œâ”€â”€ config.py                    # ì„¤ì • íŒŒì¼
â”œâ”€â”€ .gitignore                   # Git ì œì™¸ íŒŒì¼
â”‚
â”œâ”€â”€ litevlm/                     # ë©”ì¸ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ __init__.py             # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”‚   â”œâ”€â”€ model.py                # LiteVLM ë©”ì¸ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ vision_encoder.py       # Vision Encoder (InternViT + Patch Selection)
â”‚   â”œâ”€â”€ text_decoder.py         # Text Decoder (Qwen2)
â”‚   â”œâ”€â”€ token_compression.py    # Visual Token Compression
â”‚   â””â”€â”€ speculative_decode.py   # Speculative Decoding
â”‚
â”œâ”€â”€ scripts/                     # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ download_models.py      # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
â”‚   â”œâ”€â”€ convert_to_tensorrt.py  # TensorRT ë³€í™˜
â”‚   â””â”€â”€ setup_jetson.sh         # Jetson ì´ˆê¸° ì„¤ì •
â”‚
â”œâ”€â”€ examples/                    # ì‚¬ìš© ì˜ˆì œ
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ basic_inference.py      # ê¸°ë³¸ ì¶”ë¡  ì˜ˆì œ
â”‚   â””â”€â”€ batch_processing.py     # ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì œ
â”‚
â”œâ”€â”€ models/                      # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
â”‚   â””â”€â”€ README.md               # ëª¨ë¸ ê´€ë¦¬ ê°€ì´ë“œ
â”‚
â”œâ”€â”€ inference.py                 # CLI ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ benchmark.py                 # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

### 1. **3ë‹¨ê³„ ìµœì í™” íŒŒì´í”„ë¼ì¸**
- âœ… **Patch Selection**: ì¤‘ìš” íŒ¨ì¹˜ë§Œ ì„ íƒí•˜ì—¬ ì—°ì‚°ëŸ‰ 3ë°° ì ˆê°
- âœ… **Token Compression**: Visual tokens ì••ì¶•ìœ¼ë¡œ LLM ì…ë ¥ ê¸¸ì´ ê°ì†Œ
- âœ… **Speculative Decoding**: ë³‘ë ¬ í† í° ìƒì„±ìœ¼ë¡œ 2-3ë°° ë””ì½”ë”© ì†ë„ í–¥ìƒ

### 2. **TensorRT ìµœì í™”**
- âœ… FP8/FP16/INT8 ì–‘ìí™” ì§€ì›
- âœ… Vision Encoder ë° Text Decoder TensorRT ë³€í™˜
- âœ… Jetson Orin ìµœì í™”

### 3. **ì‚¬ìš© í¸ì˜ì„±**
- âœ… ê°„ë‹¨í•œ Python API
- âœ… CLI ì¸í„°í˜ì´ìŠ¤
- âœ… ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
- âœ… ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬

## ğŸš€ Jetsonì—ì„œ ì‚¬ìš© ë°©ë²•

### 1ë‹¨ê³„: í´ë¡  ë° ì„¤ì •
```bash
# GitHubì— í‘¸ì‹œ í›„
git clone https://github.com/yourusername/liteVLM_injetson.git
cd liteVLM_injetson

# Jetson í™˜ê²½ ì„¤ì •
chmod +x scripts/setup_jetson.sh
./scripts/setup_jetson.sh
```

### 2ë‹¨ê³„: Python í™˜ê²½
```bash
# Conda í™˜ê²½
conda env create -f environment.yml
conda activate litevlm

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 3ë‹¨ê³„: ëª¨ë¸ ì¤€ë¹„
```bash
# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python scripts/download_models.py

# TensorRT ë³€í™˜ (FP8)
python scripts/convert_to_tensorrt.py --fp8
```

### 4ë‹¨ê³„: ì¶”ë¡  ì‹¤í–‰
```bash
# ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
python inference.py \
    --image path/to/image.jpg \
    --prompt "ì´ ì‚¬ì§„ì„ ì„¤ëª…í•´ì¤˜" \
    --stats

# ì˜ˆì œ ì‹¤í–‰
python examples/basic_inference.py

# ë²¤ì¹˜ë§ˆí¬
python benchmark.py --num-runs 100
```

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ (Jetson Orin)

| ëª¨ë¸ | ì •ë°€ë„ | ì§€ì—°ì‹œê°„ | ë©”ëª¨ë¦¬ | FPS |
|------|-------|---------|-------|-----|
| InternVL2-1B + Qwen2-1.5B | FP8 | ~45ms | 3.2GB | ~22 |
| InternVL2-1B + Qwen2-1.5B | FP16 | ~68ms | 4.8GB | ~15 |

*Jetson Orin AGX, 336Ã—336 ì´ë¯¸ì§€, 50 í† í° ìƒì„± ê¸°ì¤€

## ğŸ”§ ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### LiteVLM í´ë˜ìŠ¤ (model.py)
```python
from litevlm import LiteVLM

vlm = LiteVLM(
    vision_encoder="models/vision_encoder_fp8.engine",
    text_decoder="models/text_decoder_fp8.engine",
    token_compression=True,
    speculative_decode=True
)

result = vlm.chat(
    image="image.jpg",
    prompt="Describe this image"
)
```

### Vision Encoder (vision_encoder.py)
- InternViT ê¸°ë°˜
- Patch Selectionìœ¼ë¡œ ì¤‘ìš” íŒ¨ì¹˜ë§Œ ì„ íƒ
- TensorRT ì—”ì§„ ì§€ì›

### Text Decoder (text_decoder.py)
- Qwen2 ê¸°ë°˜
- Autoregressive ìƒì„±
- KV-cache ìµœì í™”

### Token Compression (token_compression.py)
- Adaptive pooling
- Attention-based selection
- ì••ì¶• ë¹„ìœ¨ ì¡°ì • ê°€ëŠ¥

### Speculative Decoding (speculative_decode.py)
- Draft modelë¡œ í›„ë³´ ìƒì„±
- Target modelë¡œ ê²€ì¦
- 2-3ë°° ì†ë„ í–¥ìƒ

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

### macOSì—ì„œ:
1. âœ… í”„ë¡œì íŠ¸ ì™„ì„± í™•ì¸
2. GitHub ì €ì¥ì†Œ ìƒì„±
3. ì½”ë“œ í‘¸ì‹œ:
```bash
cd /Users/limchang-geon/Desktop/liteVLM_injetson
git init
git add .
git commit -m "Initial commit: LiteVLM for Jetson Orin"
git branch -M main
git remote add origin https://github.com/yourusername/liteVLM_injetson.git
git push -u origin main
```

### Jetsonì—ì„œ:
1. ì €ì¥ì†Œ í´ë¡ 
2. í™˜ê²½ ì„¤ì • (`./scripts/setup_jetson.sh`)
3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜
4. ì¶”ë¡  ì‹¤í—˜ ì‹œì‘!

## ğŸ“ í•™ìŠµ ë¦¬ì†ŒìŠ¤

- **TensorRT ìµœì í™”**: `scripts/convert_to_tensorrt.py`
- **íŒŒì´í”„ë¼ì¸ êµ¬ì¡°**: `litevlm/model.py`
- **Patch Selection**: `litevlm/vision_encoder.py`
- **Token Compression**: `litevlm/token_compression.py`
- **Speculative Decoding**: `litevlm/speculative_decode.py`

## ğŸ› ì•Œë ¤ì§„ ì œí•œì‚¬í•­

1. **TensorRT ì—”ì§„**: Jetson Orinì—ì„œ ë¹Œë“œí•œ ì—”ì§„ì€ ë‹¤ë¥¸ GPUì—ì„œ ì‚¬ìš© ë¶ˆê°€
2. **ë©”ëª¨ë¦¬**: Jetson Orin Nano (8GB)ì—ì„œëŠ” swap ë©”ëª¨ë¦¬ í•„ìš”í•  ìˆ˜ ìˆìŒ
3. **ëª¨ë¸ í¬ê¸°**: í˜„ì¬ 1B ëª¨ë¸ ê¸°ì¤€, ë” ì‘ì€ ëª¨ë¸ ì§€ì› ì˜ˆì •

## ğŸ’¡ ìµœì í™” íŒ

1. **ì „ë ¥ ëª¨ë“œ**: `sudo nvpmodel -m 0` (MAX ì„±ëŠ¥)
2. **í´ëŸ­ ê³ ì •**: `sudo jetson_clocks`
3. **Swap í™•ì¥**: ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 8GB swap ì¶”ê°€
4. **ì••ì¶• ë¹„ìœ¨**: `config.py`ì—ì„œ ì¡°ì • ê°€ëŠ¥

## ğŸ“ ë¬¸ì œ í•´ê²°

ëª¨ë“  ë¬¸ì„œëŠ” ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ í™•ì¸ ê°€ëŠ¥:
- ë¹ ë¥¸ ì‹œì‘: `QUICKSTART.md`
- ê°œë°œ ê°€ì´ë“œ: `DEVELOPMENT.md`
- ë©”ì¸ README: `README.md`
- ëª¨ë¸ ê´€ë¦¬: `models/README.md`

---

**í”„ë¡œì íŠ¸ ì¤€ë¹„ ì™„ë£Œ!** ğŸ‰

ì´ì œ GitHubì— í‘¸ì‹œí•˜ê³  Jetsonì—ì„œ í´ë¡ í•˜ì—¬ ì‹¤í—˜ì„ ì‹œì‘í•˜ì„¸ìš”!
